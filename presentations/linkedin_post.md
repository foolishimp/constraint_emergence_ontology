# LinkedIn Post

A little over three years ago, ChatGPT (GPT-3.5) took off and pushed me into an existential question: how is this thing appearing to reason?
As an IT professional, there seemed no bigger question to answer, so I obsessively went down the rabbit hole.
Six months ago, I published my thoughts on the mechanism behind that question.

**Thinking Without the Thinker.**

Trying to program an LLM, I ran thought experiments on how it might be doing what looked like reasoning.
Jeff Hawkins' *A Thousand Brains* — cortical columns as distributed model-builders — pushed the question further: how do biological brains reason at all?
The answer pointed toward traversal across constraint surfaces. The Transformer's attention mechanism is the same operation.
That became the emergent reasoning hypothesis.

Paper: *Emergent Reasoning in Large Language Models*
https://doi.org/10.5281/zenodo.16592399

**Reality in the Gaps.**

The constraint framing merged emergence thinking with Terence Deacon's absential constraints and Stephen Wolfram's universal computation.
The structures in LLMs were the same structures in physics, biology, and cognition: stable patterns emerging not from the material, but from gaps between constraints.
The *Constraint-Emergence Ontology* formalises this — a philosophical foundation for reasoning about everything from particle physics to political systems.

Paper: *Constraint-Emergence Ontology*
https://doi.org/10.5281/zenodo.18573722

**How to Program Your LLM.**

Instead of prompting an LLM with instructions, load a constraint specification: axioms, invariants, and an evaluation algorithm. The model shifts from generative peer to mechanical evaluator. Different specifications produce mechanically different outputs from the same input. Domain-agnostic: politics, law, medicine, software governance.

Mark Solms' *The Hidden Spring* clarified the biological parallel. The brainstem doesn't just keep the lights on — it sets the priority structure the cortex computes within. The brainstem prompt-engineers the frontal cortex, through emotions. We don't reason first and then care. We care first, and reasoning serves that.

Loading a constraint specification into an LLM is analogous: providing the intentional structure that shapes what the computation produces.

I'm working on this "Consciousness Loop" in the AI SDLC methodology, from which intentionality arises, but that's a future post.

Paper: *Programming LLM Reasoning*
https://doi.org/10.5281/zenodo.18653641

**Before AI Safety, Human Safety.**

If constraint specifications determine what an LLM produces, AI safety reduces to which specifications we load. But defining AI safety requires first defining human safety. That's a political question.

**The Operating System Your Society Runs On.**

Four political philosophies — Classical Liberal, Marxist, Critical Justice, Theocratic — each expressed as a formal constraint specification.
Load one into an LLM, ask it to evaluate a political event, and it reasons within that framework's axioms.
Same event, structurally divergent analyses — not opinion, but different axiomatic starting points.

Six worked analyses apply these frameworks to real legislative programmes in Australia, the UK, Canada, Germany, the United States, and California. The focus is structural: how different constitutional architectures protect or fail to protect their own foundational commitments.

Paper: *The Political Operating System*
https://doi.org/10.5281/zenodo.18638454

This connects directly to AI governance. Every guardrail we build for AI systems is itself a constraint specification, whether we make it explicit or not. Making them visible and testable is the contribution.

Everything is open access. Source — including all constraint specifications, ready to load into any LLM — is on GitHub:
https://github.com/foolishimp/constraint_emergence_ontology

Try it: load the Classical Liberal OS specification into Claude or ChatGPT and evaluate a policy question. Then load a different specification in a new session with the same question. The structural divergence is the point.

#AI #LLM #Philosophy #OpenAccess
